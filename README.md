# ğŸ§  The Unsupervised Image Organizer

**Visualizing High-Dimensional Image Clusters using CNN Embeddings, PCA & t-SNE**

<p align="center">
  <img src="https://img.shields.io/badge/Deep%20Learning-TensorFlow-orange"/>
  <img src="https://img.shields.io/badge/Clustering-Unsupervised-purple"/>
  <img src="https://img.shields.io/badge/Visualization-3D%20Interactive-blue"/>
  <img src="https://img.shields.io/badge/Deployment-Streamlit-red"/>
</p>

> **Goal:**  
> Take a messy pile of unlabeled images and automatically organize them into meaningful visual groups â€” without using a single label â€” and explore those groups interactively in 3D.

Here I Have Used CIFAR-10 Dataset, it has 10000 images, but i have considered only first 1000 images,  
**Link ğŸ‘‰**
[Click Here](https://www.kaggle.com/c/cifar-10)

This project demonstrates how **semantic structure can emerge from data alone** by combining deep feature extraction, dimensionality reduction, and unsupervised clustering, packaged as a fast, interactive system.

---

## ğŸš€ Why This Project Matters


**Insted of Doing Clustering Tabular Data, Static 2D Plots, We can be**
- Working with a **unstructured image data**
- Using a **pre-trained CNN as a feature extractor**
- Separating **modeling**, **visualization**, and **deployment**
- Building an **interactive system**

The result feels closer to a lightweight, unsupervised version of *Google Photos clustering* â€” but built from first principles.

---

## ğŸ§© High-Level Pipeline


```
Raw Images
      â†“
CNN Feature Extraction (MobileNetV2)
      â†“
1280-D Semantic Embeddings
      â†“
PCA (Noise Filtering & Compression)
      â†“
t-SNE (3D Visualization Space)
      â†“
Unsupervised Clustering (K-Means / DBSCAN)
      â†“
Interactive 3D Exploration (Streamlit + Plotly)
```

Each stage is intentionally isolated so the system is:
- **Debuggable**
- **Reproducible**
- **Fast at runtime**

---

## ğŸ“ Repository Structure

```
unsupervised-image-organizer/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                  # Streamlit application
â”‚   â”œâ”€â”€ image_data.npy          # Raw images (runtime artifact)
â”‚   â”œâ”€â”€ pca_features.npy        # PCA-compressed embeddings
â”‚   â”œâ”€â”€ tsne_3d.npy             # 3D visualization coordinates
â”‚   â””â”€â”€ image_features.npy      # CNN embeddings
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_feature_extraction.ipynb
â”‚   â”œâ”€â”€ 02_dimensionality_reduction.ipynb
â”‚   â””â”€â”€ 03_clustering.ipynb
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ pipeline_diagram.png
â”‚
â”œâ”€â”€ viz_data.csv                # Final visualization + cluster metadata
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

**Design choice:** Heavy computation happens once in notebooks. The Streamlit app only loads artifacts â†’ no recomputation, fast UX.

---

## ğŸ§  Key Design Decisions (Engineering Rationale)

### ğŸ”¹ Why not cluster raw pixels?

Pixel distances are extremely fragile â€” a 1-pixel shift completely changes the math.

**Fix:** Use a pre-trained CNN to extract semantic embeddings that encode:
- Texture
- Shape
- Object parts
- Visual context

### ğŸ”¹ Why MobileNetV2?

- Lightweight and fast
- Pre-trained on ImageNet
- Excellent trade-off between speed and semantic quality
- Ideal for feature extraction, not classification

### ğŸ”¹ Why PCA before t-SNE?

- t-SNE is slow and unstable in very high dimensions
- PCA removes noise and compresses global structure
- PCA acts as a semantic filter, not just a math trick

**PCA is used here as meaning compression, not visualization.**

### ğŸ”¹ Why not cluster on t-SNE output?

t-SNE distorts global distances and is not mathematically suitable for clustering.

**Correct approach:**
- Cluster in PCA space
- Visualize in t-SNE space

![alt text](image-1.png)



---

## ğŸ” Clustering Strategy

### K-Means
- Forces a fixed number of clusters
- Useful for testing whether embeddings naturally separate into groups
- Provides stable, interpretable partitions


### DBSCAN
- Density-based clustering
- No need to specify number of clusters
- Naturally detects outliers and ambiguous images

**Using both highlights the difference between:**
- *Forcing structure* vs *discovering structure*

---

## ğŸ–¥ï¸ Interactive Application

![alt text](image.png)

The Streamlit app provides:

âœ¨ 3D interactive visualization (Plotly)  
ğŸ¨ Color-coded clusters  
ğŸ” Hover-based inspection  
ğŸ” Manual image lookup via ID  
ğŸ”„ Toggle between clustering strategies

This turns abstract embeddings into human-interpretable insight.

---

## âš™ï¸ Tech Stack

| Component | Technology |
|-----------|-----------|
| Deep Learning | TensorFlow / Keras |
| Feature Extraction | MobileNetV2 (pre-trained) |
| Dimensionality Reduction | PCA, t-SNE |
| Clustering | K-Means, DBSCAN |
| Data Processing | NumPy, Pandas |
| Visualization | Plotly (3D interactive) |
| Deployment | Streamlit |

---

## â–¶ï¸ Running the App Locally


1. **Clone the repository**
   ```bash
   git clone [LINK](https://github.com/Shreyas-S-809/Unsupervised-Image-Organizer)
   cd Unsupervised-Image-Organiser
   ```

2. **Initialize and Activate Virtual Environment**
   ```powershell
   # Create environment
   python -m venv en

   # Activate (Windows)
   en\Scripts\activate
   ```

3. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the Application**
   ```bash
   streamlit run app/app.py
   ```

All heavy ML computation is already done â€” the app loads instantly.


---

## ğŸ“Œ Possible Extensions

- Swap CIFAR-10 for a custom image dataset
- Add cluster filtering & search
- Introduce a feedback loop for human-in-the-loop refinement
- Replace t-SNE with UMAP for faster scaling
- Deploy with Docker / Hugging Face Spaces

---

## ğŸ Final Note

This project was intentionally designed to show that:

> **Unsupervised learning is not about accuracy â€” it is about structure, assumptions, and interpretation.**

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Built with ğŸ§  and â˜•**
**Thank You! ğŸ™Œ**